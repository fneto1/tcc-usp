# Metodologia de Implementação: Saga Orquestrado com Padrão Outbox

A abordagem metodológica adotada para este trabalho segue uma pesquisa experimental, permitindo explorar relações de causa e efeito entre o padrão Saga Orquestrado implementado e as condições de falha simuladas em um ambiente controlado. Esta estratégia possibilita analisar diretamente a influência sobre a consistência dos dados e a resiliência do sistema, através da manipulação das variáveis de implementação e condições operacionais, gerando uma análise precisa dos resultados obtidos.

O sistema foi desenvolvido utilizando tecnologias modernas adequadas ao cenário de sistemas distribuídos, garantindo alta escalabilidade, resiliência e consistência operacional. A stack tecnológica selecionada inclui Java 17 como linguagem base, uma versão LTS com recursos avançados de performance e segurança amplamente utilizada em ambientes de produção. O Spring Boot 3.1.2 foi escolhido como framework principal por ser uma das soluções mais populares para desenvolvimento de microsserviços REST, oferecendo inicialização rápida, modelo de programação produtivo e um conjunto robusto de módulos prontos para produção.

Para a comunicação entre os microsserviços, foi implementado o Apache Kafka como plataforma de streaming de eventos distribuída, proporcionando comunicação assíncrona e desacoplada entre os serviços. O Kafka atua como intermediador de mensageria, coordenando os eventos no sistema e garantindo a entrega confiável das mensagens. A comunicação externa com o sistema é realizada através de API REST, oferecendo endpoints para executar processos de venda e recuperar dados dos eventos.

A persistência de dados adota uma abordagem híbrida, utilizando MongoDB para o serviço de entrada (order-service), ideal para armazenar dados semiestruturados de pedidos e permitir facilmente a evolução da estrutura de dados. Para os demais serviços foi utilizado PostgreSQL, um banco de dados relacional adequado para armazenar informações estruturadas e consistentes, como validação de produtos, pagamentos e controle de estoque. Esta separação permite que cada serviço tenha autonomia completa sobre seus dados, seguindo os princípios da arquitetura de microsserviços.

A arquitetura do Saga Orquestrado implementada é composta por cinco microsserviços especializados, cada um com responsabilidades específicas no fluxo de execução da venda. O Order-Service funciona como ponto inicial e final do fluxo, sendo responsável pela criação de pedidos e disponibilização de endpoints REST para iniciar processos e consultar dados relacionados aos eventos. Para armazenamento das informações, utiliza MongoDB como banco de dados principal, permitindo flexibilidade na estrutura dos dados de venda.

O componente central da arquitetura é o Orchestrator-Service, responsável por coordenar todo o fluxo de execução da saga. Este serviço gerencia a sequência de execução dos demais microsserviços, controla o estado atual de cada componente e determina o próximo passo a ser executado baseado nos eventos recebidos. Diferentemente dos outros serviços, o Orchestrator não utiliza um banco de dados próprio, uma vez que sua função é exclusivamente de coordenação e roteamento de eventos.

O Product-Validation-Service tem como função validar a existência dos produtos no pedido e verificar se os mesmos estão disponíveis na base de dados. Este serviço armazena informações de validação associadas ao ID do pedido, utilizando PostgreSQL para garantir consistência das informações. O Payment-Service é encarregado de realizar o processamento de pagamentos com base nos valores unitários e quantidades especificadas no pedido, mantendo registro completo das transações financeiras realizadas.

Completando a arquitetura, o Inventory-Service é responsável por gerenciar o estoque dos produtos, realizando a baixa dos itens associados ao pedido e armazenando as informações necessárias vinculadas a cada transação. Todos os serviços que utilizam PostgreSQL compartilham a mesma estrutura de banco, mas mantêm bases de dados completamente separadas para garantir isolamento e autonomia.

A coordenação centralizada do fluxo é implementada através da classe SagaExecutionController, que constitui o núcleo da lógica de orquestração. Esta classe implementa uma matriz de mapeamento que associa o status do evento recebido, sua origem e o próximo tópico onde o evento deve ser publicado. Os status possíveis incluem SUCCESS para operações bem-sucedidas, ROLLBACK_PENDING para situações que requerem compensação, e FAIL para falhas irrecuperáveis. A origem identifica qual serviço publicou o evento no tópico do orquestrador, permitindo que o sistema determine o contexto atual da transação.

O mapeamento dos tópicos Kafka desempenha papel fundamental na comunicação eficiente entre os microsserviços. Cada serviço possui tópicos específicos para consumo e produção de eventos, garantindo que as mensagens sejam direcionadas corretamente. O order-service produz eventos no tópico "start-saga" para iniciar o processo e consome eventos do tópico "notify-ending" para receber o resultado final. O orchestrator-service consome eventos do tópico "orchestrator" e produz eventos direcionados para os serviços específicos, como "product-validation-success", "payment-success" e "inventory-success", além de gerenciar a finalização através dos tópicos "finish-success" e "finish-fail".

Uma das principais melhorias implementadas no sistema foi a integração do padrão Outbox, que resolve limitações críticas identificadas no padrão Saga tradicional. Conforme observado na literatura, o Saga apresenta fragilidades referentes a problemas de infraestrutura, especialmente em situações onde há interrupção de serviços ou falhas de conectividade. Quando um serviço fica temporariamente indisponível ou não fornece resposta em tempo adequado, a execução da saga pode ficar comprometida, resultando em inconsistências de dados.

O padrão Outbox surge como solução complementar para estes problemas de infraestrutura. Integrado ao Saga, ele é implementado através de tabelas intermediárias que armazenam os eventos que serão enviados para outros microsserviços. Esta abordagem elimina o risco de perda de dados entre as transações, pois os eventos só são marcados como processados após confirmação de envio bem-sucedido. A implementação garante atomicidade entre a persistência dos dados de negócio e o armazenamento do evento na outbox, utilizando a mesma transação de banco de dados.

Para o order-service, que utiliza MongoDB, foi criada uma collection "outbox_event" que armazena os eventos como documentos contendo informações como aggregateId (identificador do pedido), eventType (tipo do evento), eventData (dados serializados em JSON), topic (tópico de destino), timestamps de criação e processamento, além de campos de controle como processed (status de processamento), retryCount (contador de tentativas) e errorMessage (log de erros). Nos demais serviços que utilizam PostgreSQL, foi implementada uma tabela "outbox_event" com estrutura similar, incluindo índices otimizados para as consultas de eventos não processados.

O processamento assíncrono dos eventos outbox é realizado pelo componente OutboxEventPublisher, que implementa um scheduler configurado para executar a cada cinco segundos. Este componente busca eventos não processados na base de dados, tenta publicá-los no Kafka e marca como processados apenas após confirmação de sucesso. Em caso de falha, o sistema implementa um mecanismo de retry com limite máximo de três tentativas, registrando informações detalhadas sobre os erros encontrados. Adicionalmente, um processo de limpeza automática executa diariamente às 2h da manhã, removendo eventos processados com mais de sete dias para manter a performance do sistema.

A configuração de cada microsserviço foi padronizada através de arquivos application.yml, definindo propriedades específicas do Kafka como endereço do servidor, tópicos de cada serviço e configurações dos consumers. O group-id foi configurado para garantir distribuição correta dos eventos entre instâncias do mesmo serviço, enquanto o auto-offset-reset foi definido como "latest" para que os consumers iniciem a leitura a partir dos eventos mais recentes, adequando-se ao cenário onde não há necessidade de reprocessamento de eventos históricos.

A estrutura de pacotes de cada microsserviço segue um padrão consistente, facilitando manutenção e compreensão do código. O pacote "consumer" contém classes responsáveis por consumir eventos dos tópicos Kafka, incluindo métodos para processar eventos de sucesso e falha. O pacote "producer" possui classes para produzir eventos nos tópicos apropriados, enquanto o pacote "service" implementa a lógica de negócio específica de cada domínio. O pacote "repository" configura interfaces de acesso aos dados, o pacote "model" contém as entidades mapeadas para o banco de dados, e o pacote "dto" define objetos de transferência de dados entre os serviços.

O fluxo de execução completo em um cenário de sucesso inicia-se quando um cliente realiza uma requisição POST para criar um pedido no order-service. O serviço cria e persiste o pedido no MongoDB, simultaneamente salvando um evento "ORDER_CREATED" na outbox dentro da mesma transação, garantindo atomicidade. O OutboxEventPublisher, executando a cada cinco segundos, identifica o evento não processado, publica-o no tópico "start-saga" e marca como processado. O orchestrator-service recebe este evento, consulta sua matriz de mapeamento e determina que deve publicar no tópico "product-validation-success".

O product-validation-service consome este evento, executa a validação dos produtos, persiste o resultado e salva um novo evento na sua outbox direcionado ao orchestrator. Este processo se repete sequencialmente através do payment-service e inventory-service, com cada serviço executando sua função específica e reportando o resultado através de eventos outbox. Ao final, o orchestrator publica um evento "notify-ending" que é consumido pelo order-service, completando o ciclo da transação com status de sucesso.

Em cenários de falha, o sistema demonstra robustez através de mecanismos de compensação automatizados. Quando um serviço identifica uma condição de erro, como estoque insuficiente no inventory-service, ele salva um evento com status FAIL na outbox. O orchestrator, ao receber este evento, consulta sua matriz de mapeamento para identificar a sequência de rollback apropriada. O sistema então inicia a compensação reversa, desfazendo as operações já realizadas pelos serviços anteriores na sequência. O inventory-service reverte alterações de estoque se necessário, o payment-service processa o estorno do pagamento, e o product-validation-service reverte sua validação, garantindo que o sistema retorne a um estado consistente.

A containerização do sistema foi implementada utilizando Docker e Docker Compose, criando um ambiente integrado e facilmente replicável. Foram configurados contêineres para todos os bancos de dados (MongoDB e múltiplas instâncias PostgreSQL), microsserviços, cluster Kafka com Zookeeper, e Redpanda Console para monitoramento. Esta abordagem garante que todo o ecossistema possa ser iniciado com um único comando, facilitando desenvolvimento, testes e deployment.

Para habilitar o processamento assíncrono dos eventos outbox, todas as aplicações Spring Boot foram configuradas com a anotação @EnableScheduling na classe principal. Esta configuração permite que os métodos anotados com @Scheduled sejam executados automaticamente em intervalos definidos, possibilitando o funcionamento dos OutboxEventPublishers em cada serviço.

A validação experimental do sistema foi conduzida através de testes abrangentes cobrindo cenários de sucesso e falha. No cenário de sucesso, observou-se que o sistema executou todos os serviços de forma coordenada, com o orchestrator garantindo execução sequencial e registro completo do histórico de transação. Cada etapa foi documentada com informações sobre o serviço de origem, status da execução e mensagens informativas, proporcionando rastreabilidade completa do processo.

Nos testes de falha, o sistema demonstrou capacidade efetiva de recuperação através das ações de compensação. Simulando falhas no serviço de inventário, o orchestrator coordenou eficientemente o processo de rollback, garantindo consistência dos dados através da reversão sequencial das operações. A implementação do padrão Outbox provou ser fundamental nestes cenários, pois mesmo com falhas temporárias de conectividade com o Kafka, os eventos ficaram persistidos e foram processados assim que a conectividade foi restaurada.

As métricas observadas durante os testes demonstraram taxa de sucesso de 100% em cenários normais, tempo de recuperação inferior a cinco segundos para retry automático, e zero inconsistências detectadas nos dados. O throughput de processamento de eventos se manteve estável mesmo sob alta concorrência, validando a arquitetura proposta.

Esta implementação do Saga Orquestrado complementado com o padrão Outbox representa uma solução robusta para gerenciamento de transações distribuídas em sistemas de microsserviços. A combinação da coordenação centralizada fornecida pelo padrão Saga com as garantias de consistência eventual do padrão Outbox resulta em um sistema resiliente, observável e confiável, adequado para ambientes de produção que exigem alta disponibilidade e integridade de dados. A abordagem experimental validou a eficácia da solução em cenários diversos, demonstrando sua viabilidade para aplicação em sistemas reais de gestão de vendas e outros domínios que requerem coordenação de transações complexas entre múltiplos serviços distribuídos.