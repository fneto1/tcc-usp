# Metodologia de Implementação do Padrão Saga Coreografado com Outbox Pattern

A abordagem adotada para este trabalho é a de pesquisa experimental, devido à necessidade de analisar o comportamento do padrão Saga Coreografado em um ambiente controlado. Este tipo de pesquisa permite explorar relações de causa e efeito entre as variáveis envolvidas, como os padrões implementados entre os microsserviços e as condições de falha simuladas, buscando entender a influência sobre a consistência dos dados envolvidos na transação e a resiliência do sistema.

Neste projeto, foi implementado o padrão coreografado, trabalhando em cenários que simulam casos práticos, como transações de fluxo de venda padrão: validando produtos em estoque, processamento do pagamento, atualização do estoque; e simulações de falha controladas durante o fluxo de venda. Esta abordagem experimental permite que a recuperação das transações em um cenário de falha e a consistência dos dados entre os serviços sejam observados de forma direta, pois permite a manipulação das variáveis de implementação e condições operacionais, gerando uma análise precisa dos resultados obtidos.

Os sistemas de gerenciamento dos microsserviços foram implementados utilizando tecnologias modernas que são adequadas ao cenário de sistemas distribuídos. É necessário garantir que o sistema seja altamente escalonável, resiliente e que as operações sejam consistentes. As seguintes são as ferramentas/tecnologias escolhidas para a implementação do sistema e a metodologia escolhida para finalizar o projeto: Java 17 e Spring Boot 3, tratando-se de uma versão estável do Java amplamente usada para a produção de aplicativos devido aos seus recursos avançados, responsivos e seguros. O Spring Boot 3 é um dos frameworks mais populares para o desenvolvimento de aplicações REST em uma arquitetura de microsserviços, simplificando a criação de serviços com inicialização rápida, com um modelo de programação produtivo, além de fornecer um conjunto robusto de módulos e ferramentas prontos para produção.

Apache Kafka foi utilizado como plataforma de streaming de eventos distribuída, que proporciona uma comunicação assíncrona e desacoplada entre microsserviços. O Kafka coordena os eventos no sistema, atuando como um intermediador de mensageria entre os serviços. Para armazenamento de dados, o sistema adotou uma abordagem de banco de dados híbrida. Para o serviço de entrada foi utilizado um banco NoSQL, o MongoDB, ideal para armazenar dados semiestruturados e permite facilmente a evolução da estrutura de dados da venda. Para os demais serviços foi utilizado o PostgreSQL, um banco de dados relacional adequado para armazenar informações estruturadas e consistentes, como validação de produtos, pagamentos e estoque.

Docker foi utilizado para conteinerizar cada microsserviço e seu ambiente, permitindo facilmente a replicação e implantação do sistema. Com o uso de Docker Compose, foi possível gerenciar a execução do contêiner garantindo que todos os serviços como Kafka, MongoDB, PostgreSQL sejam iniciados e devidamente configurados, facilitando a criação e a execução do sistema. O Redpanda Console foi implementado como plataforma de gerenciamento e monitoramento das mensagens trocadas entre os microsserviços a partir do Kafka, permitindo a visualização dos eventos em tempo real, permitindo a análise dos dados de comunicação.

Diferente do padrão orquestrado, no coreografado não há mais o serviço central orquestrador que tinha a responsabilidade de coordenar o fluxo da operação, determinando qual seria a próxima ação. Agora, cada microsserviço possui a obrigação de fazer o gerenciamento dos seus eventos. Esta autonomia é implementada a partir do pacote Saga, presente em todos os serviços, contendo a classe SagaExecutionController. Esta classe atua como o processador de cada microsserviço, implementando métodos que tratam os eventos recebidos a partir dos consumers e decidem para qual tópico produzir o evento tratado, eliminando a necessidade de um serviço específico para realizar essa lógica.

O sistema foi estruturado com quatro microsserviços principais. O Order-Service atua como ponto inicial e final do fluxo, sendo responsável pela criação inicial de um pedido e disponibilizando endpoints REST para iniciar o processo e consultar os dados relacionados aos eventos. Para armazenamento das informações dos eventos, é utilizado o banco de dados MongoDB. O Product-Validation-Service tem como função validar a existência de um produto no pedido e também se o mesmo existe na base de dados, armazenando a validação do produto associado ao ID do pedido. O Payment-Service é encarregado de realizar o processamento de pagamentos com base nos valores unitários e quantidades de cada item especificado no pedido, armazenando as informações relacionadas a pagamentos de cada um dos pedidos executados. O Inventory-Service é responsável por dar a baixa no estoque dos produtos associados a um pedido, armazenando as informações necessárias vinculadas a cada ID do pedido. Os três últimos serviços utilizam PostgreSQL como banco de dados.

Para fortalecer a robustez do sistema, foi implementado o padrão Outbox integrado ao Saga Coreografado. O padrão Outbox surge para resolver problemas referentes à infraestrutura, sendo implementado a partir de uma tabela intermediária que armazena os dados de saída que serão enviados para outro microsserviço, eliminando o risco de perda de dados entre as transações caso haja alguma falha no processo, pois os dados só serão enviados ao próximo serviço se a operação for realizada com sucesso. Para cada microsserviço, foram implementados componentes específicos: entidades OutboxEvent para PostgreSQL e MongoDB, repositórios OutboxEventRepository com queries específicas para eventos não processados, serviços OutboxEventService para gerenciamento transacional de eventos, e OutboxEventPublisher para publicação assíncrona via scheduler.

A estrutura da tabela outbox_event foi padronizada entre os serviços PostgreSQL, contendo campos para identificação única, agregado de origem, tipo de evento, dados do evento, destino, timestamps de criação e processamento, controle de retry e mensagens de erro. O padrão Outbox implementado garante atomicidade através da persistência de dados de negócio e eventos na mesma transação, consistência mantendo o estado sempre sincronizado entre serviços, durabilidade assegurando que eventos nunca sejam perdidos, e at-least-once delivery com garantia de entrega através de retry automático.

Definido os serviços que compõe a arquitetura, o próximo passo foi o mapeamento dos tópicos. Esta etapa é crucial, pois a partir dela é possível garantir uma comunicação eficiente e consistente entre os microsserviços. Os tópicos desempenham um papel de um canal de mensagens, permitindo a troca de informações entre os serviços, garantindo que cada etapa do fluxo seja efetuada de forma coordenada e confiável, realizando o tratamento apropriado em situações de falhas e permitindo a rastreabilidade das operações.

Após o mapeamento dos tópicos, foi definida a infraestrutura de contêineres utilizando Docker. Estruturado a partir do docker-compose.yml para criar e gerenciar os contêineres necessários para a execução da aplicação. Foram configurados contêineres para os bancos de dados, microsserviços, Kafka e o Redpanda console, garantindo um ambiente integrado e funcional para o sistema.

Em cada microsserviço foi preciso definir algumas propriedades do Kafka a partir do arquivo application.yml, definindo algumas informações como o endereço do servidor do Kafka, os tópicos específicos de cada serviço e as propriedades dos consumers, o group-id, responsável por garantir que os eventos sejam distribuídos de forma correta entre as instâncias do mesmo serviço e o auto-offset-reset definido como latest, que certifica que os consumers iniciem a leitura dos eventos a partir do offset mais recente, se adequando ao cenário onde não há a necessidade de reprocessamento de eventos mais antigos.

Essas informações foram utilizadas em outro arquivo chamado KafkaConfig.java. A função deste arquivo é implementar as funções que são responsáveis por fazer as configurações dos consumers e producers e criar os tópicos necessários para o funcionamento da aplicação. Concluída a etapa de configuração do Kafka para cada serviço e com os tópicos configurados, o próximo passo foi a implementação das lógicas dos microsserviços garantindo que cada serviço execute sua respectiva tarefa e sua comunicação de forma eficiente.

Estes serviços foram projetados para consumir e produzir eventos em tópicos específicos, seguindo o fluxo da coreografia. Cada serviço possui uma estrutura de pacotes padronizada, adotando boas práticas de desenvolvimento de software. O pacote Consumer possui classes que são responsáveis por consumir os eventos publicados nos tópicos do Kafka, contendo métodos que processam eventos com status de sucesso ou falha. O pacote DTO contém os objetos de transferência de dados, essas classes são utilizadas para determinar os dados que serão exibidos e trocados entre os microsserviços. O pacote Enums contém classes do tipo enum que armazenam constantes que serão utilizadas durante a execução dos serviços. O pacote Model possui as entidades que são mapeadas para as tabelas do banco de dados. O pacote Producer possui a classe responsável por produzir eventos de sucesso ou falha nos tópicos do Kafka. O pacote Repository configura as interfaces que acessam o banco de dados e métodos específicos para a busca de informações. O pacote Service implementa a lógica com as regras de negócio de cada microsserviço. O pacote Saga contém classes que têm como responsabilidade coordenar o fluxo de execução dos eventos distribuídos, definindo qual será o próximo serviço a ser executado.

O pacote Saga desempenha um papel fundamental no gerenciamento descentralizado do fluxo da transação distribuída. Neste pacote está contida a classe SagaExecutionController que determina quais tópicos serão utilizados para publicação com base nas informações presentes no evento processado localmente. Diferente do padrão orquestrado, cada serviço mantém sua própria lógica de decisão baseada no status do evento recebido, contexto local do serviço e regras de negócio específicas.

Para garantir a robustez transacional, foram implementadas configurações específicas do padrão Outbox. O scheduler foi configurado com intervalo de execução de 5 segundos, retry automático de até 3 tentativas e processamento em lote de eventos pendentes. As configurações foram definidas através do parâmetro outbox.max-retry-count com valor 3, permitindo múltiplas tentativas de entrega antes de marcar um evento como falhado.

A metodologia de testes implementada abrangeu cenários de sucesso e falha. No cenário de sucesso, foi realizado o fluxo completo de venda com todos os serviços executando corretamente, validando a consistência final dos dados. No cenário de falha, foram simuladas situações de indisponibilidade de estoque, verificando o processo de compensação automática e analisando a integridade dos dados após rollback. Para observabilidade, foram implementados logs estruturados em cada serviço, rastreamento de eventos via Redpanda Console e histórico completo de transações no banco.

As métricas de avaliação consideram a consistência através da verificação do estado final dos dados, resiliência analisando o comportamento em cenários de falha, performance medindo o tempo de processamento end-to-end, e observabilidade avaliando a capacidade de rastreamento e debug. Esta abordagem metodológica permite uma análise abrangente da eficácia do padrão Saga Coreografado integrado ao Outbox Pattern, demonstrando sua viabilidade para sistemas de gestão de vendas com robustez transacional e autonomia distribuída.